{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T23:57:13.078783Z",
     "iopub.status.busy": "2023-03-17T23:57:13.077845Z",
     "iopub.status.idle": "2023-03-17T23:57:13.092412Z",
     "shell.execute_reply": "2023-03-17T23:57:13.091095Z",
     "shell.execute_reply.started": "2023-03-17T23:57:13.078745Z"
    },
    "id": "BlIfrc1Gl2fu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import List, Union, Iterator, Tuple, Any\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Input, Activation, Flatten, Lambda, Resizing, MaxPooling2D,  Conv2D, Concatenate, UpSampling2D, Cropping2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.applications import mobilenet_v2, inception_v3, resnet, vgg16, xception, EfficientNetV2S, EfficientNetV2B0, mobilenet_v3\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, TensorBoard, History, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, RMSprop, SGD, Adagrad, Nadam\n",
    "from keras.losses import mean_squared_error\n",
    "import keras_tuner as kt\n",
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "IMG_HEIGHT = 160 # image height\n",
    "IMG_WIDTH = 200 # image width\n",
    "CHANNELS = 3 # choose 1 if you're working with grayscale images else 3\n",
    "BATCH_SIZE = 32 # number of images to process in one batch\n",
    "epochs = 100 # number of epochs\n",
    "step_size = 100 # number of steps per epoch\n",
    "val_step_size = 80 # number of steps per epoch for validation data\n",
    "data_path='./machine-learning-in-science-ii-2023' # parent path to training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:37.582989Z",
     "iopub.status.busy": "2023-03-17T23:56:37.582697Z",
     "iopub.status.idle": "2023-03-17T23:56:37.595473Z",
     "shell.execute_reply": "2023-03-17T23:56:37.594541Z",
     "shell.execute_reply.started": "2023-03-17T23:56:37.582964Z"
    },
    "id": "0cmhIYoJn-V0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Loads data from csv file\n",
    "    Params\n",
    "    ------\n",
    "    data_path: str\n",
    "        Data path containing images and csv data\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Loaded data as pandas dataframe\n",
    "    \"\"\"\n",
    "    columns = ['image_id', 'angle', 'speed']\n",
    "    data = pd.read_csv(os.path.join(data_path, 'training_norm.csv'), delimiter= ',', header=0, names = columns)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:37.597362Z",
     "iopub.status.busy": "2023-03-17T23:56:37.597072Z",
     "iopub.status.idle": "2023-03-17T23:56:37.608576Z",
     "shell.execute_reply": "2023-03-17T23:56:37.607567Z",
     "shell.execute_reply.started": "2023-03-17T23:56:37.597337Z"
    },
    "id": "9xggw4koo26n",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Appends absolute path with image id column\n",
    "def append_path(data: pd.DataFrame, data_path: os.PathLike) -> pd.DataFrame:\n",
    "  data['image_id'] = data.image_id.apply(lambda x: os.path.join(data_path, 'training_data/', str(x)) + '.png')\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWsOtfs-o8SQ"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:37.610139Z",
     "iopub.status.busy": "2023-03-17T23:56:37.609823Z",
     "iopub.status.idle": "2023-03-17T23:56:37.619261Z",
     "shell.execute_reply": "2023-03-17T23:56:37.618326Z",
     "shell.execute_reply.started": "2023-03-17T23:56:37.610112Z"
    },
    "id": "6TMHCf2Go-nC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train test split of dataset\n",
    "def split_data(data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    data: pd.DataFrame\n",
    "        Pandas dataframe containing all data.\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[pd.DataFrame, pd.DataFrame]\n",
    "        A tuple of train and val split\n",
    "    \"\"\"\n",
    "    rnd = np.random.RandomState(seed=None)\n",
    "\n",
    "    train_data, val_data = train_test_split(data, test_size=0.2, random_state=rnd.seed(1234)) # split data with test size of 20%\n",
    "    #test_data, val_data = train_test_split(train_data, test_size=0.12, random_state=rnd.seed(1234)) # split validation data with test size of 12.5%\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:37.622551Z",
     "iopub.status.busy": "2023-03-17T23:56:37.621683Z",
     "iopub.status.idle": "2023-03-17T23:56:37.638621Z",
     "shell.execute_reply": "2023-03-17T23:56:37.637780Z",
     "shell.execute_reply.started": "2023-03-17T23:56:37.622521Z"
    },
    "id": "Ti7mUZzHKJa4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:37.640164Z",
     "iopub.status.busy": "2023-03-17T23:56:37.639858Z",
     "iopub.status.idle": "2023-03-17T23:56:37.650872Z",
     "shell.execute_reply": "2023-03-17T23:56:37.649944Z",
     "shell.execute_reply.started": "2023-03-17T23:56:37.640137Z"
    },
    "id": "sEErtJDaKTqQ",
    "outputId": "da41ac5c-cec2-4a23-d6c7-041528ea4906",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   image_id   angle  speed\n0         1  0.4375    0.0\n1         2  0.8125    1.0\n2         3  0.4375    1.0\n3         4  0.6250    1.0\n4         5  0.5000    0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>angle</th>\n      <th>speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.4375</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.8125</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.4375</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.6250</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.5000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:37.652167Z",
     "iopub.status.busy": "2023-03-17T23:56:37.651894Z",
     "iopub.status.idle": "2023-03-17T23:56:37.716624Z",
     "shell.execute_reply": "2023-03-17T23:56:37.715658Z",
     "shell.execute_reply.started": "2023-03-17T23:56:37.652144Z"
    },
    "id": "cQ_RoYeBKXqB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = append_path(data, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:37.718058Z",
     "iopub.status.busy": "2023-03-17T23:56:37.717778Z",
     "iopub.status.idle": "2023-03-17T23:56:37.724303Z",
     "shell.execute_reply": "2023-03-17T23:56:37.723444Z",
     "shell.execute_reply.started": "2023-03-17T23:56:37.718034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'./machine-learning-in-science-ii-2023/training_data/2.png'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image_id should contain complete path for images \n",
    "data['image_id'].tolist()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data.to_csv('./new_training_data.csv', sep=',')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:37.725700Z",
     "iopub.status.busy": "2023-03-17T23:56:37.725444Z",
     "iopub.status.idle": "2023-03-17T23:56:37.735690Z",
     "shell.execute_reply": "2023-03-17T23:56:37.734789Z",
     "shell.execute_reply.started": "2023-03-17T23:56:37.725677Z"
    },
    "id": "4ikSujIRK058",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# splitting data into training and validation set\n",
    "train_data, val_data = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:37.738942Z",
     "iopub.status.busy": "2023-03-17T23:56:37.738610Z",
     "iopub.status.idle": "2023-03-17T23:56:37.744803Z",
     "shell.execute_reply": "2023-03-17T23:56:37.743894Z",
     "shell.execute_reply.started": "2023-03-17T23:56:37.738916Z"
    },
    "id": "xLyPZ2tjpCEh",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plotting distribution of output labels\n",
    "def visualize(data):\n",
    "    plt.hist(data.loc[:,'angle'])\n",
    "    plt.hist(data.loc[:,'speed'])\n",
    "    plt.legend(['Steering angle', 'Driving speed'])\n",
    "    plt.title('Distribution plot for steering angle and speed')\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:37.746148Z",
     "iopub.status.busy": "2023-03-17T23:56:37.745894Z",
     "iopub.status.idle": "2023-03-17T23:56:38.025551Z",
     "shell.execute_reply": "2023-03-17T23:56:38.024548Z",
     "shell.execute_reply.started": "2023-03-17T23:56:37.746125Z"
    },
    "id": "HZsDngK805Ap",
    "outputId": "dc67edeb-fd54-4371-ec8e-1eb054829647",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting train_data\n",
    "visualize(data=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BCbMBY8pJad"
   },
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modify_rgb(img, height: int = 224, width: int= 224, color_mode: str='rgb'):\n",
    "    img = tf.image.resize(img, size=(height, width)) # resize image to given height and width\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32) # convert image to float32\n",
    "    if color_mode == 'yuv':\n",
    "        # normalize pixel values between -1 and 1\n",
    "        img = tf.image.per_image_standardization(img)\n",
    "        img = tf.image.rgb_to_yuv(img) # convert image to YUV\n",
    "    elif color_mode == 'grayscale':\n",
    "        img = tf.image.per_image_standardization(img) # normalize pixel values between -1 and 1\n",
    "        img = tf.image.rgb_to_grayscale(img) # convert to Grayscale\n",
    "    elif color_mode == 'hsv':\n",
    "        img = tf.image.rgb_to_hsv(img) # convert image to YUV\n",
    "        img = tf.image.per_image_standardization(img) # normalize pixel values between -1 and 1\n",
    "    else:\n",
    "        img = tf.image.per_image_standardization(img) # normalize pixel values between -1 and 1\n",
    "    # return modified image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:38.027203Z",
     "iopub.status.busy": "2023-03-17T23:56:38.026894Z",
     "iopub.status.idle": "2023-03-17T23:56:38.039886Z",
     "shell.execute_reply": "2023-03-17T23:56:38.038888Z",
     "shell.execute_reply.started": "2023-03-17T23:56:38.027177Z"
    },
    "id": "XPc65R3CpE37",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate images on the fly while training model\n",
    "def img_generator(train_data: pd.DataFrame, test_dir: os.PathLike, val_data: pd.DataFrame, BATCH_SIZE: int, IMG_HEIGHT: int, IMG_WIDTH: int, color_mode: str='rgb') -> Tuple[Iterator, Iterator, Iterator]:\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    train_data: pd.DataFrame\n",
    "        Pandas dataframe containing training data\n",
    "    test_dir: os.PathLike\n",
    "        Path containing testing data\n",
    "    val_data: pd.DataFrame\n",
    "        Pandas dataframe containing validation data\n",
    "    BATCH_SIZE: int\n",
    "        Number of images to process in each batch\n",
    "    IMG_HEIGHT: int\n",
    "        image height\n",
    "    IMG_WIDTH: int\n",
    "        image width\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Iterator, Iterator, Iterator]\n",
    "        keras ImageDataGenerators used for training and validating model.\n",
    "    \"\"\"\n",
    "    # Define partial function to pass image height and width to preprocessing function\n",
    "    preprocess_input = partial(modify_rgb, height=IMG_HEIGHT, width=IMG_WIDTH, color_mode=color_mode)\n",
    "    # Define a dictionary of arguments for the data generators\n",
    "    datagen_args = dict(\n",
    "        #rescale=(1.0 / 255), # normalize pixels in range 0 and 1\n",
    "        rotation_range=20,\n",
    "        shear_range=0.1,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        brightness_range=(0.65, 1.2),\n",
    "        zoom_range=(0.70, 1.2),\n",
    "        fill_mode='reflect',\n",
    "        samplewise_center=False,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False\n",
    "        )\n",
    "\n",
    "    # Define data generators with datagen arguments\n",
    "    train_generator = ImageDataGenerator(**datagen_args, preprocessing_function=preprocess_input)\n",
    "    test_generator = ImageDataGenerator(**datagen_args, preprocessing_function=preprocess_input)\n",
    "    val_generator = ImageDataGenerator(**datagen_args, preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "    train_generator = train_generator.flow_from_dataframe(dataframe=train_data,\n",
    "                                                          directory=None,\n",
    "                                                          x_col='image_id',\n",
    "                                                          y_col=['angle','speed'],\n",
    "                                                          target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                          color_mode='rgb',\n",
    "                                                          class_mode='raw',\n",
    "                                                          batch_size=BATCH_SIZE,\n",
    "                                                          seed=tf.random.set_seed(1234),\n",
    "                                                          shuffle=True)\n",
    "\n",
    "    test_generator = test_generator.flow_from_directory(directory=test_dir,\n",
    "                                                        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                        color_mode='rgb',\n",
    "                                                        class_mode=None,\n",
    "                                                        classes=None,\n",
    "                                                        batch_size=1, # Process whole batch at once\n",
    "                                                        seed=tf.random.set_seed(1234),\n",
    "                                                        shuffle=False)\n",
    "\n",
    "    val_generator = val_generator.flow_from_dataframe(dataframe=val_data,\n",
    "                                                      directory=None,\n",
    "                                                      x_col='image_id',\n",
    "                                                      y_col=['angle', 'speed'],\n",
    "                                                      target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                      color_mode='rgb',\n",
    "                                                      class_mode='raw',\n",
    "                                                      batch_size=BATCH_SIZE,\n",
    "                                                      seed=tf.random.set_seed(1234),\n",
    "                                                      shuffle=True)\n",
    "                                                      #save_to_dir='machine-learning-in-science-ii-2023/augmentations', save_format='png')\n",
    "\n",
    "    return train_generator, test_generator, val_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:38.041255Z",
     "iopub.status.busy": "2023-03-17T23:56:38.041011Z",
     "iopub.status.idle": "2023-03-17T23:56:43.197941Z",
     "shell.execute_reply": "2023-03-17T23:56:43.196645Z",
     "shell.execute_reply.started": "2023-03-17T23:56:38.041233Z"
    },
    "id": "e2qxYfeC1uim",
    "outputId": "6e5e1fb0-ac21-4f02-b996-5a0b331f27ac",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11034 validated image filenames.\n",
      "Found 1020 images belonging to 1 classes.\n",
      "Found 2759 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create data generators for train test and val data\n",
    "#training_ds, testing_ds, validation_ds = create_img_pipeline(train_ds, test_ds, val_ds)\n",
    "test_dir = os.path.join(data_path, 'test_data')\n",
    "\n",
    "train_generator, test_generator, val_generator = img_generator(train_data, test_dir, val_data, BATCH_SIZE=BATCH_SIZE, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for batch in range(1):\n",
    "    next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMSECallback(Callback):\n",
    "    def __init__(self, test_generator):\n",
    "        super().__init__()\n",
    "        self.test_generator = test_generator\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_true = self.test_generator.labels\n",
    "        y_pred = self.model.predict(self.test_generator)\n",
    "        mse = mean_squared_error(y_true, y_pred).numpy()\n",
    "        logs['test_mse'] = float(mse)\n",
    "        print(f'MSE on test data at the end of epoch {epoch+1}: {float(mse):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to adjust learning rate if val_loss has seen no improvements after 5 epochs\n",
    "class CustomLearningRateScheduler(Callback):\n",
    "    \"\"\"Custom Learning rate scheduler which sets learning rate according to a schedule\"\"\"\n",
    "    def __init__(self, factor=0.1, patience=5, verbose=0):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose if verbose is not None else 0\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.wait = 0\n",
    "        self.new_lr = None # Initialize new_lr to None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = logs.get('val_loss')\n",
    "\n",
    "        if val_loss < self.best_val_loss: # if current val_loss is less than best_val_loss\n",
    "            self.best_val_loss = val_loss # update new best_val_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1 # Start wait timer\n",
    "            if self.wait >= self.patience and self.new_lr is None:\n",
    "                old_lr = float(backend.get_value(self.model.optimizer.learning_rate))\n",
    "                self.new_lr = old_lr * self.factor\n",
    "            if self.verbose == 1:\n",
    "                print(f'\\nEpoch {epoch}: Reducing learning rate to {self.new_lr:.6f}')\n",
    "            backend.set_value(self.model.optimizer.learning_rate, self.new_lr)\n",
    "            self.wait = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Custom callback to end training when val_loss is NaN\n",
    "class TerminateOnNaN(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = logs.get('val_loss')\n",
    "        if val_loss is not None and np.isnan(val_loss):\n",
    "            print('Validation loss is NaN. Stopping training.')\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T23:56:43.199776Z",
     "iopub.status.busy": "2023-03-17T23:56:43.199411Z",
     "iopub.status.idle": "2023-03-17T23:56:43.208718Z",
     "shell.execute_reply": "2023-03-17T23:56:43.207823Z",
     "shell.execute_reply.started": "2023-03-17T23:56:43.199746Z"
    },
    "id": "o5T5ByyEx5HA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# defining callbacks\n",
    "def get_callbacks(model: str) -> List[Union[TensorBoard, EarlyStopping, ModelCheckpoint, LearningRateScheduler]]:\n",
    "    \"\"\"Accepts the model name as a string and returns multiple keras callbacks\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    model: str\n",
    "        The name of model as a string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of multiple keras callbacks\n",
    "    \"\"\"\n",
    "    logdir = (\n",
    "        'logs/scalars/' + model + '_' + datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    ) # logging for each model\n",
    "    tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.001,  # model should improve by at least 0.1\n",
    "        patience=20,  # amount of epochs  with improvements worse than 1% until the model stops\n",
    "        verbose=1,\n",
    "        baseline=0.009,\n",
    "        mode='min',\n",
    "        restore_best_weights=True,  # restore the best model with the lowest validation error\n",
    "    )\n",
    "\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        './data/models/' + model + '.h5',\n",
    "        monitor='val_loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,  # save the best model\n",
    "        mode='min',\n",
    "        save_freq='epoch',  # save the model on disk at end of every epoch\n",
    "    )\n",
    "\n",
    "    #lr_callback = LearningRateScheduler(schedule_decay)\n",
    "    reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                    factor=0.1,\n",
    "                                    patience=10,\n",
    "                                    cooldown=5,\n",
    "                                    verbose=1,\n",
    "                                    mode='min',\n",
    "                                    min_delta=0.0001,\n",
    "                                    min_lr=1e-9\n",
    "    )\n",
    "    #custom_lr_callback = CustomLearningRateScheduler()\n",
    "    term_on_nan_callback = TerminateOnNaN()\n",
    "\n",
    "    return [tensorboard_callback, early_stopping_callback, model_checkpoint_callback, reduce_lr_callback, term_on_nan_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Define train method\n",
    "def train(name: str, model: Model, train_generator: Iterator, val_generator: Iterator, epochs: int, BATCH_SIZE: int, step_size: int, val_step_size: int) -> History:\n",
    "    \"\"\"Used to train a model\n",
    "    Params\n",
    "    ------\n",
    "    name: str\n",
    "        Model name\n",
    "    model: keras.models.Model\n",
    "        Model we are training\n",
    "    train_generator: Iterator=\n",
    "        Image data generator for training\n",
    "    test_generator: Iterator\n",
    "        Image data generator for testing\n",
    "    val_generator: Iterator\n",
    "        Image data generator for validation\n",
    "    epoch: int\n",
    "        Number of epochs to train for\n",
    "    Returns\n",
    "    -------\n",
    "    keras.callbacks.History\n",
    "    \"\"\"\n",
    "    callbacks = get_callbacks(name)\n",
    "\n",
    "    history = model.fit(train_generator,\n",
    "              epochs=epochs,\n",
    "              steps_per_epoch=step_size,\n",
    "              validation_data=val_generator,\n",
    "              validation_steps=val_step_size,\n",
    "              callbacks=callbacks,\n",
    "              workers=6,\n",
    "              verbose=1,\n",
    "              batch_size=BATCH_SIZE)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_block(input, filters, kernel_size, strides: Any=(1,1), padding: str='same', activation: str='relu'):\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding)(input)\n",
    "    x = Activation(activation)(x)\n",
    "    #x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Custom activation function\n",
    "@tf.function\n",
    "def mish(x):\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reference to original paper: https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "def create_nvidia_model(input_shape, dropout_rate, optimizer) -> Model:\n",
    "    \"\"\"Creates cnn model based on architecture proposed by NVIDIA\n",
    "    Parmas\n",
    "    -------\n",
    "    input_shape: Any\n",
    "    dropout_rate: float\n",
    "    optimizer: keras.optimizers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    # Define kernel_initializers\n",
    "    glorot_init = tf.keras.initializers.GlorotNormal(seed=42)\n",
    "    he_init = tf.keras.initializers.HeNormal(seed=42)\n",
    "\n",
    "    # Define model\n",
    "    model = Sequential(name='nvidia_model')\n",
    "    # Cropping input image from 240x320 to 370x110\n",
    "    model.add(Cropping2D(cropping=((0, 130), (85, 5)), input_shape=input_shape))\n",
    "\n",
    "    # Resizing cropped image from 370x110 to 250x70\n",
    "    model.add(Lambda(lambda x: tf.image.resize(x, size=[70, 250])))\n",
    "\n",
    "    # Convolution blocks\n",
    "    model.add(Conv2D(36, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer=he_init, input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2), padding='valid'))\n",
    "\n",
    "    model.add(Conv2D(48, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer=he_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2), padding='valid'))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer=he_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu', kernel_initializer=he_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu', kernel_initializer=he_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "    #model.add(GlobalAveragePooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1000, activation='relu', kernel_initializer=he_init))\n",
    "    #model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer=he_init))\n",
    "    #model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(2, activation='sigmoid', kernel_initializer=glorot_init))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mse', 'accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Autoencoder implementation\n",
    "def create_autoencoder_model(input_shape, dropout_rate, optimizer) -> Model:\n",
    "    \"\"\"Creates an autoencoder model\n",
    "    Params\n",
    "    ------\n",
    "    input_shape: input dimensions of image (224x224x3).\n",
    "    dropout_rate: Applies Dropout to the input, to prevent over-fitting.\n",
    "    optimizer: Optimization algorithm.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Sequential\n",
    "        The keras model.\n",
    "    \"\"\"\n",
    "    # Define model\n",
    "\n",
    "    inputs = Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "    num_angle_classes = 100\n",
    "    num_speed_classes = 2\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1')(inputs)\n",
    "    x = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    conv2 = Conv2D(16, (3, 3),  activation='relu', padding='same', name='conv2')(pool1)\n",
    "    x = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    conv3 = Conv2D(8, (3, 3),  activation='relu', padding='same', name='conv3')(pool2)\n",
    "    x = BatchNormalization()(conv3)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # Decoder\n",
    "    deconv1 = Conv2D(8, (3, 3), activation='relu', padding='same', name='deconv1')(encoded)\n",
    "    x = BatchNormalization()(deconv1)\n",
    "    up1 = UpSampling2D((2, 2))(x)\n",
    "\n",
    "    deconv2 = Conv2D(16, (3, 3), strides=(1, 1), activation='relu', padding='same', name='deconv2')(up1)\n",
    "    x = BatchNormalization()(deconv2)\n",
    "    up2 = UpSampling2D((2, 2))(x)\n",
    "\n",
    "    deconv3 = Conv2D(32, (3, 3), strides=(1, 1), activation='relu', padding='same', name='deconv3')(up2)\n",
    "    x = BatchNormalization()(deconv3)\n",
    "    up3 = UpSampling2D((2, 2))(x)\n",
    "\n",
    "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same', name='decoded')(up3)\n",
    "    #decoded = GlobalAveragePooling2D(name='decoded')(decoded)\n",
    "\n",
    "    # Define autoencoder\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    # Compile autoencoder\n",
    "    autoencoder.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics='accuracy')\n",
    "\n",
    "    # Define encoder model to use for predictions\n",
    "    # add dense layers on top of endoded layer\n",
    "    flat = Flatten()(encoded)\n",
    "    fc1 = Dense(128, activation='relu')(flat)\n",
    "    fc2 = Dense(64, activation='relu')(fc1)\n",
    "    y = Dropout(dropout_rate)(fc2)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    # Define output layers\n",
    "    angle_output = Dense(num_angle_classes, name='angle_output', activation='softmax')(y)\n",
    "    speed_output = Dense(num_speed_classes, name='speed_output', activation='softmax')(y)\n",
    "    concatenated = Concatenate()([angle_output, speed_output])\n",
    "    outputs = Dense(2, activation='linear')(concatenated)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss=['mean_squared_error'],\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mse', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates hybrid model by combining steering_net and speed_net\n",
    "def create_hybrid_model(input_shape, dropout_rate, optimizer) -> Model:\n",
    "    \"\"\"Creates a hybrid model to make two separate predictions on steering angle and speed.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    input_shape: input dimensions of images\n",
    "    dropout_rate: Applies Dropout to the input, to prevent over-fitting.\n",
    "    optimizer: Optimization algorithm.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Sequential\n",
    "        The keras model.\n",
    "    \"\"\"\n",
    "    # Define kernel_initializers for Dense layers\n",
    "    glorot_init = tf.keras.initializers.GlorotNormal(seed=42)\n",
    "    he_init = tf.keras.initializers.HeNormal(seed=42)\n",
    "\n",
    "    # Define input\n",
    "    inputs = Input(\n",
    "        shape=input_shape\n",
    "    )\n",
    "    ## Define steering_net ##\n",
    "    #########################\n",
    "    steering_net = Sequential([\n",
    "        # Preprocessing\n",
    "        Cropping2D(cropping=((62, 62), (62, 62)), input_shape=input_shape), # Crop input image\n",
    "        Lambda(lambda x: tf.image.resize(x, (100, 100))), # Resize image\n",
    "        # Convolutional layers\n",
    "        Conv2D(filters=32, kernel_size=5, strides=(2, 2), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2), padding='same'),\n",
    "        Conv2D(filters=32, kernel_size=5, strides=(2, 2), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2), padding='same'),\n",
    "        Conv2D(filters=64, kernel_size=5, strides=(2, 2), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2), padding='same'),\n",
    "        Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2), padding='same'),\n",
    "        Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2), padding='same'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        # Flatten the convolution output\n",
    "        Flatten(),\n",
    "        BatchNormalization(), # to reduce covariate shift\n",
    "        # Fully-connected layers, returning single output\n",
    "        Dense(100, activation='relu', kernel_initializer=he_init),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(50, activation='relu', kernel_initializer=he_init),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(10, activation='relu', kernel_initializer=he_init),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='softmax', kernel_initializer=glorot_init)], name='steering_net')\n",
    "\n",
    "    ## Define speed_net ##\n",
    "    ######################\n",
    "    # use mobilenet as base\n",
    "    base = xception.Xception(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layers in base.layers[:20]:\n",
    "        layers.trainable = False\n",
    "    # Rebuild top\n",
    "    speed_net = Sequential([\n",
    "        base,\n",
    "        GlobalAveragePooling2D(),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu', kernel_initializer=he_init),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(512, activation='relu', kernel_initializer=he_init),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(128, activation='relu', kernel_initializer=he_init),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid', kernel_initializer=glorot_init)\n",
    "    ], name='speed_net')\n",
    "\n",
    "    # Merge both models\n",
    "    merged = Concatenate()([steering_net(inputs), speed_net(inputs)])\n",
    "    outputs = Dense(2, activation='linear', name='output')(merged)\n",
    "    # Define final model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_baseline_model(input_shape, dropout_rate, optimizer) -> Sequential:\n",
    "    \"\"\"Creates baseline model using TL\n",
    "    Parmas\n",
    "    -------\n",
    "    input_shape: Any\n",
    "    dropout_rate: float\n",
    "    optimizer: keras.optimizers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    # Define number of classes for both outputs\n",
    "    #num_angle_classes = 100\n",
    "    #num_speed_classes = 10\n",
    "    # Define kernel_initializers for Dense layers\n",
    "    glorot_init = tf.keras.initializers.GlorotNormal(seed=42)\n",
    "    he_init = tf.keras.initializers.HeNormal(seed=42)\n",
    "\n",
    "    \"\"\"\n",
    "    top = base.output\n",
    "\n",
    "    base.trainable = False # Freeze the model\n",
    "    for layers in base.layers[:40]:\n",
    "        layers.trainable = False\n",
    "\n",
    "    #top = base.output\n",
    "    pool = GlobalAveragePooling2D()(top)\n",
    "    #flat = Flatten()(pool)\n",
    "    dropout1 = Dropout(dropout_rate)(pool)\n",
    "    fc1 = Dense(1024, activation='elu', kernel_initializer=he_init)(dropout1)\n",
    "    batch_norm1 = BatchNormalization()(fc1)\n",
    "\n",
    "    dropout2 = Dropout(dropout_rate)(batch_norm1)\n",
    "    fc2 = Dense(512, activation='elu', kernel_initializer=he_init)(dropout2)\n",
    "    batch_norm2 = BatchNormalization()(fc2)\n",
    "\n",
    "    dropout3 = Dropout(dropout_rate)(batch_norm2)\n",
    "    fc3 = Dense(64, activation='elu', kernel_initializer=he_init)(dropout3)\n",
    "    batch_norm3 = BatchNormalization()(fc3)\n",
    "\n",
    "    fc4 = Dense(num_angle_classes, activation='softmax', kernel_initializer=glorot_init)(batch_norm3)\n",
    "    angle_output = BatchNormalization(name='angle_output')(fc4)\n",
    "\n",
    "    fc5 = Dense(num_speed_classes, activation='softmax', kernel_initializer=glorot_init)(batch_norm3)\n",
    "    speed_output = BatchNormalization(name='speed_output')(fc5)\n",
    "\n",
    "    concatenated = Concatenate()([angle_output, speed_output])\n",
    "    outputs = Dense(2, activation='sigmoid', kernel_initializer=glorot_init)(concatenated)\n",
    "\n",
    "    model = Model(inputs=base.input, outputs=outputs)\"\"\"\n",
    "    # Define model\n",
    "    base = xception.Xception(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    base.trainable = False # Freeze model\n",
    "    for layers in base.layers[-9:]:\n",
    "        layers.trainable = True\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer=he_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer=he_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer=he_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer=he_init))\n",
    "    model.add(Dense(2, activation='softplus', kernel_initializer=glorot_init))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  metrics=['mse', 'accuracy'],\n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 5, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,989,450\n",
      "Trainable params: 1,126,562\n",
      "Non-trainable params: 20,862,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, CHANNELS)\n",
    "\n",
    "lr = 2e-3 # learning rate\n",
    "decay = 0.001 # weight decay\n",
    "dropout_rate = 0.2\n",
    "optimizer = Nadam(learning_rate=lr)  # optimizer\n",
    "\n",
    "baseline_model = create_baseline_model(input_shape, dropout_rate, optimizer)\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session() # clear keras session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 10/100 [==>...........................] - ETA: 18s - loss: 0.4390 - mse: 0.4390 - accuracy: 0.6219"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Prod_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (-2 for input with 1 dimension(s) [Op:Prod]\nTraceback (most recent call last):\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/engine/data_adapter.py\", line 901, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 823, in get\n    raise e\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 814, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/multiprocessing/pool.py\", line 771, in get\n    raise self._value\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 600, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 385, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.standardize(x)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 1849, in standardize\n    x = self.preprocessing_function(x)\n\n  File \"<ipython-input-14-9459467cad89>\", line 15, in modify_rgb\n    img = tf.image.per_image_standardization(img) # normalize pixel values between -1 and 1\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 7215, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Prod_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (-2 for input with 1 dimension(s) [Op:Prod]\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_10]]\n  (1) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Prod_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (-2 for input with 1 dimension(s) [Op:Prod]\nTraceback (most recent call last):\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/engine/data_adapter.py\", line 901, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 823, in get\n    raise e\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 814, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/multiprocessing/pool.py\", line 771, in get\n    raise self._value\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 600, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 385, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.standardize(x)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 1849, in standardize\n    x = self.preprocessing_function(x)\n\n  File \"<ipython-input-14-9459467cad89>\", line 15, in modify_rgb\n    img = tf.image.per_image_standardization(img) # normalize pixel values between -1 and 1\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 7215, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Prod_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (-2 for input with 1 dimension(s) [Op:Prod]\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_12227]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mdevice(device_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGPU:0\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m----> 2\u001B[0m     baseline_history \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbaseline_model\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbaseline_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_generator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mstep_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_step_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_step_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[22], line 24\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(name, model, train_generator, val_generator, epochs, BATCH_SIZE, step_size, val_step_size)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"Used to train a model\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03mParams\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m------\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;124;03mkeras.callbacks.History\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     22\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m get_callbacks(name)\n\u001B[0;32m---> 24\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m          \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_step_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m          \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m          \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m          \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m          \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m history\n",
      "File \u001B[0;32m~/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     53\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mUnknownError\u001B[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Prod_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (-2 for input with 1 dimension(s) [Op:Prod]\nTraceback (most recent call last):\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/engine/data_adapter.py\", line 901, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 823, in get\n    raise e\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 814, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/multiprocessing/pool.py\", line 771, in get\n    raise self._value\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 600, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 385, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.standardize(x)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 1849, in standardize\n    x = self.preprocessing_function(x)\n\n  File \"<ipython-input-14-9459467cad89>\", line 15, in modify_rgb\n    img = tf.image.per_image_standardization(img) # normalize pixel values between -1 and 1\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 7215, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Prod_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (-2 for input with 1 dimension(s) [Op:Prod]\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_10]]\n  (1) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Prod_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (-2 for input with 1 dimension(s) [Op:Prod]\nTraceback (most recent call last):\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/engine/data_adapter.py\", line 901, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 823, in get\n    raise e\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 814, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/multiprocessing/pool.py\", line 771, in get\n    raise self._value\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/utils/data_utils.py\", line 600, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 385, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.standardize(x)\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/keras/preprocessing/image.py\", line 1849, in standardize\n    x = self.preprocessing_function(x)\n\n  File \"<ipython-input-14-9459467cad89>\", line 15, in modify_rgb\n    img = tf.image.per_image_standardization(img) # normalize pixel values between -1 and 1\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/Users/rahuln/opt/miniconda/envs/picarnet/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 7215, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Prod_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (-2 for input with 1 dimension(s) [Op:Prod]\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_12227]"
     ]
    }
   ],
   "source": [
    "with tf.device(device_name='GPU:0'):\n",
    "    baseline_history = train(name='baseline_model', model=baseline_model, train_generator=train_generator, val_generator=val_generator, epochs=epochs, BATCH_SIZE=BATCH_SIZE,  step_size=step_size, val_step_size=val_step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hyperparameter tuning using Keras-Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model tuning function\n",
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Build model for hyperparamter tuning\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    hp: HyperParameters class instance\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Model: Keras model object\n",
    "    \"\"\"\n",
    "    # Define number of classes for both outputs\n",
    "    #num_angle_classes = 1024\n",
    "    #num_speed_classes = 100\n",
    "\n",
    "    # Define kernel_initializers for Dense layers\n",
    "    glorot_init = tf.keras.initializers.GlorotNormal(seed=42)\n",
    "    he_init = tf.keras.initializers.HeNormal(seed=42)\n",
    "\n",
    "    # Define input\n",
    "    input_shape = (224, 224, 3)\n",
    "\n",
    "    # Define base model\n",
    "    base = xception.Xception(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "    # Define hyper-parameter tuning space\n",
    "    # Choice of baseline model\n",
    "    \"\"\" baseline_choice = hp.Choice(name = 'baseline', values=['resnet50', 'mobilenetv2', 'vgg16'], ordered=False)\n",
    "    if baseline_choice == 'resnet50':\n",
    "        hp_baseline = resnet.ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    elif baseline_choice == 'mobilenetv2':\n",
    "        hp_baseline = mobilenet_v2.MobileNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    else:\n",
    "        hp_baseline = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\"\"\"\n",
    "    # Tune dropout rate\n",
    "    hp_dropout_rate = hp.Choice(name = 'dropout_rate', values=[2e-1, 3e-1, 4e-1, 5e-1])\n",
    "    # Choose layers to freeze in base model\n",
    "    #hp_layers_to_freeze = hp.Int(name = 'layers_to_freeze', min_value=0, max_value=len(hp_baseline.layers), step=2)\n",
    "    hp_layers_to_train = hp.Int('layers_to_train', min_value=1, max_value=20, step=2)\n",
    "    # Tune the kernel size in convolution layers\n",
    "    #hp_kernel_size = hp.Choice(name='kernel_size', values=[3, 5])\n",
    "    # Tune the number of strides in convolution layers\n",
    "    #hp_strides = hp.Choice(name='strides', values=[1, 2])\n",
    "    # Tune the number of units in the Dense layers\n",
    "    hp_units1 = hp.Choice(name='dense1', values=[256, 512, 1024], ordered=False)\n",
    "    hp_units2 = hp.Choice(name='dense2', values=[64, 128, 256], ordered=False)\n",
    "    hp_units3 = hp.Choice(name='dense3', values=[16, 32, 64], ordered=False)\n",
    "    #hp_units4 = hp.Choice(name='dense4', values=[8, 16, 32, 64, 128, 256, 512], ordered=False)\n",
    "    #hp_l2 = hp.Choice(name = 'kernel_regularizer', values=[0.1, 0.01, 0.001])\n",
    "    hp_activation = hp.Choice(name = 'activation', values=['relu', 'elu'], ordered=False)\n",
    "    #hp_output_activation = hp.Choice(name = 'output_activation', values=['linear', 'sigmoid'], ordered=False)\n",
    "    # Tune momentum with RMSprop optimizer\n",
    "    hp_momentum = hp.Choice(name='momentum', values=[0.0, 0.1, 0.01, 0.99, 0.001, 0.0001])\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from different values of learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[2e-3, 4e-3, 7e-3, 6e-4])\n",
    "    # Choose optimal weight decay\n",
    "    hp_decay = hp.Choice(name='decay', values=[1e-3, 2e-3, 2e-4])\n",
    "    # choose optimal optimizer\n",
    "    optimizer_choice = hp.Choice('optimizer', ['Adam', 'Nadam', 'Adagrad', 'RMSprop'], ordered=False)\n",
    "    if optimizer_choice == 'Adam':\n",
    "        hp_optimizer = Adam(learning_rate=hp_learning_rate, decay=hp_decay)\n",
    "    elif optimizer_choice == 'Nadam':\n",
    "        hp_optimizer = Nadam(learning_rate=hp_learning_rate, decay=hp_decay)\n",
    "    elif optimizer_choice == 'Adagrad':\n",
    "            hp_optimizer = Adagrad(learning_rate=hp_learning_rate)\n",
    "    else:\n",
    "        hp_optimizer = RMSprop(learning_rate=hp_learning_rate, momentum=hp_momentum, decay=hp_decay)\n",
    "\n",
    "    base.trainable = False # Freeze the model\n",
    "    for layer in base.layers[-hp_layers_to_train:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top\n",
    "    model = Sequential(name='tuned_baseline_model')\n",
    "    model.add(base)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(hp_dropout_rate))\n",
    "    model.add(Dense(hp_units1, kernel_initializer=he_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(hp_activation))\n",
    "    model.add(Dropout(hp_dropout_rate))\n",
    "    model.add(Dense(hp_units2, kernel_initializer=he_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(hp_activation))\n",
    "    model.add(Dropout(hp_dropout_rate))\n",
    "    model.add(Dense(hp_units3, kernel_initializer=he_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(hp_activation))\n",
    "    model.add(Dropout(hp_dropout_rate))\n",
    "    model.add(Dense(32, activation=hp_activation, kernel_initializer=he_init))\n",
    "    model.add(Dense(2, activation='linear', kernel_initializer=glorot_init))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=hp_optimizer,\n",
    "                  metrics=['mse', 'accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_dir = (\n",
    "        'logs/tuned_scalars/' + 'tuned_baseline_model' + '_' + datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    ) # dir to save tuning logs\n",
    "\n",
    "# Define tuner\n",
    "tuner = kt.BayesianOptimization(hypermodel=build_model,\n",
    "                    objective=kt.Objective('val_loss', direction='min'),\n",
    "                    max_trials=5,\n",
    "                    overwrite=True,\n",
    "                    directory='./data/tuned_models/',\n",
    "                    project_name='tuned_baseline_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session() # clear keras session before starting search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuner.search(train_generator,\n",
    "             epochs = 100,\n",
    "             callbacks = [\n",
    "                 EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001),\n",
    "                 TensorBoard(log_dir=tuning_dir),\n",
    "                 ModelCheckpoint('./data/tuned_models/tuned_baseline/best_weights.h5',save_best_only=True, monitor='val_loss'),\n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_lr=1e-9, patience=5, cooldown=5, min_delta=0.00001),\n",
    "                 TerminateOnNaN(),\n",
    "                 CustomLearningRateScheduler()\n",
    "             ],\n",
    "             validation_data=val_generator,\n",
    "             batch_size = BATCH_SIZE,\n",
    "             steps_per_epoch = 150,\n",
    "             validation_steps = 80\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_params = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session() # clear keras session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_history = train(name='tuned_baseline_model', model=best_model, train_generator=train_generator, val_generator=val_generator, epochs=50, BATCH_SIZE=BATCH_SIZE,  step_size=step_size, val_step_size=val_step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    loss_list = ['loss']\n",
    "    val_loss_list = ['val_loss']\n",
    "\n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return\n",
    "\n",
    "    ## As loss always exists\n",
    "    epochs = np.arange(0,len(history.history[loss_list[0]]))\n",
    "\n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs - 0.5, history.history[l], 'lightblue', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'coral', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "\n",
    "    plt.title('Tuned-Baseline Model: Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(False)\n",
    "    plt.legend()\n",
    "    #plt.savefig('baseline_model_loss_plot.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_loss(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-17T23:56:44.935873Z",
     "iopub.status.idle": "2023-03-17T23:56:44.936202Z",
     "shell.execute_reply": "2023-03-17T23:56:44.936047Z",
     "shell.execute_reply.started": "2023-03-17T23:56:44.936031Z"
    },
    "id": "vjC71urSx_df",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(test_generator: Iterator, model: Sequential) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    test_generator: Iterator\n",
    "        Data generator for testing\n",
    "    model: Sequential model\n",
    "        trained model to make\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        predictions as pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # extract image_id from test_generator\n",
    "    image_ids = [filename.split('/')[1] for filename in test_generator.filenames]\n",
    "    # convert to pandas dataframe with image_id as column name\n",
    "    png_df = pd.DataFrame(data=image_ids, columns=['image_id'])\n",
    "    png_df['image_id'] = png_df.image_id.apply(lambda x: os.path.split(x)[-1].split('.png')[0])\n",
    "\n",
    "    # make predictions\n",
    "    pred = model.predict(test_generator)\n",
    "\n",
    "    # convert prediction numpy.ndarray( to pd.DataFrame\n",
    "    pred_df = pd.concat([png_df, pd.DataFrame(data=pred, columns=['angle', 'speed'])], axis=1)\n",
    "    # dropping index from dataframe\n",
    "    pred_df.reset_index(drop=True)\n",
    "\n",
    "    # return predictions\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-17T23:56:44.937725Z",
     "iopub.status.idle": "2023-03-17T23:56:44.938101Z",
     "shell.execute_reply": "2023-03-17T23:56:44.937930Z",
     "shell.execute_reply.started": "2023-03-17T23:56:44.937912Z"
    },
    "id": "raC2R1y3yAIj",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_csv(pred_df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    pred_df: pd.DataFrame\n",
    "        predictions in pandas dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    savedir='./submissions' # submissions directory\n",
    "    if not os.path.exists(savedir):\n",
    "        os.mkdir(savedir)\n",
    "\n",
    "    csvfile = 'submission' + '_' + datetime.now().strftime('%d-%b_%I-%M%p') + '.csv' # csv file name\n",
    "    savedir = str(os.path.join(savedir, csvfile))\n",
    "    pred_df.to_csv(savedir, sep=',', index=False) # save to disk\n",
    "    print('Saved CSV file on disk!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2023-03-17T23:56:44.939105Z",
     "iopub.status.idle": "2023-03-17T23:56:44.939514Z",
     "shell.execute_reply": "2023-03-17T23:56:44.939317Z",
     "shell.execute_reply.started": "2023-03-17T23:56:44.939293Z"
    },
    "id": "5NulLTRvUx2v",
    "outputId": "55e607e0-d919-4e45-a0e1-de5b608b7bb1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#test_path = os.path.join(data_path, 'test_data', 'images') # path to test data\n",
    "#test_dir = os.path.join(data_path, 'test_data')\n",
    "pred_df = get_predictions(test_generator, baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-03-17T23:56:44.943443Z",
     "iopub.status.idle": "2023-03-17T23:56:44.943876Z",
     "shell.execute_reply": "2023-03-17T23:56:44.943690Z",
     "shell.execute_reply.started": "2023-03-17T23:56:44.943669Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_csv(pred_df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
